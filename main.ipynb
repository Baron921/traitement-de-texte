{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**LECTURE D'UN FICHIER AVEC UNE BIBLIOTHÈQUE PYTHON**",
   "id": "310d1e2d7c9c6e29"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-01T18:32:43.787492736Z",
     "start_time": "2026-02-01T18:32:43.330022870Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "with open(os.getcwd()+ '/texte.txt') as file:\n",
    "    fileData = file.read()\n",
    "\n",
    "# Affichage des 200 premiers caractères du fichier\n",
    "fileData[0:200]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Si vous vous intéressez au big data, vous connaissez certainement Apache Spark. Savez-vous pourquoi Spark est le framework de prédilection pour le traitement de données massives ? Pourquoi est-il auta'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**LECTURE AVEC NLTK CORPUS READER**",
   "id": "1159b0048cdf6e99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:35:57.806460602Z",
     "start_time": "2026-02-01T18:35:57.652174460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "# Permet de lire une liste de fichier texte dans un repertoire.\n",
    "# Chaque fichier texte devient un identifiant de fichier unique mais le contenu de chaque est ensemble dans un seul corpus.\n",
    "# Les données sont dévisées en paragraphes, phrases et tokens pendant que le corpus est lu.\n",
    "corpus = PlaintextCorpusReader(os.getcwd(), 'texte.txt')\n",
    "\n",
    "# Afficher le contenu brut du corpus\n",
    "corpus.raw()"
   ],
   "id": "5f0b149911f0b050",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Si vous vous intéressez au big data, vous connaissez certainement Apache Spark. Savez-vous pourquoi Spark est le framework de prédilection pour le traitement de données massives ? Pourquoi est-il autant apprécié notamment pour déployer les algorithmes de machine learning ? Découvrez ce cours sur Apache PySpark pour répondre à toutes vos questions. À travers de multiples exemples et mises en pratique, le professeur associé en technologies de l'information et techniques d'optimisation, vous donne toutes les clés pour analyser efficacement des données à grande échelle avec Apache Spark et Python.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**EXPLORATION DU CORPUS**",
   "id": "fadcb751d5b13b33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T19:13:54.149007544Z",
     "start_time": "2026-02-01T19:13:53.955905033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extraire l'ID de chaque fichier...\n",
    "print(\"Fichier dans le corpus  : \", corpus.fileids())\n",
    "\n",
    "# Extraire les paragraphes du corpus (ils sont identifiés par une ligne blanche séparant le texte)\n",
    "paragraphs = corpus.paras()\n",
    "print(\"Nombre total de paragraphes du corpus : \", len(paragraphs))\n",
    "\n",
    "# Extraire les phrases du corpus\n",
    "sentences = corpus.sents()\n",
    "print(\"Nombre total de phrases du corpus : \", len(sentences))\n",
    "print(\"Première phrase : \", sentences[0])\n",
    "\n",
    "# Extraire des mots du corpus\n",
    "print(\"Nombre de mots dans le corpus : \", len(corpus.words()))\n",
    "print(\"Mots dans le corpus : \", corpus.words())\n"
   ],
   "id": "d42a11aa1008137c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier dans le corpus  :  ['texte.txt']\n",
      "Nombre total de paragraphes du corpus :  1\n",
      "Nombre total de phrases du corpus :  5\n",
      "Première phrase :  ['Si', 'vous', 'vous', 'intéressez', 'au', 'big', 'data', ',', 'vous', 'connaissez', 'certainement', 'Apache', 'Spark', '.']\n",
      "Nombre de mots dans le corpus :  103\n",
      "Mots dans le corpus :  ['Si', 'vous', 'vous', 'intéressez', 'au', 'big', ...]\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
